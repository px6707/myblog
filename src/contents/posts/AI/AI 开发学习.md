---
title: ä¼ä¸š AI å¼€å‘å­¦ä¹ 
published: 2025-01-27
description: AI å­¦ä¹ 
tags: [AI]
category: AI
licenseName: "Unlicensed"
author: panxiao
sourceLink: "https://github.com/px6707/myblog"
draft: false
---

# ä¼ä¸šçº§ AI å¼€å‘å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

> é¢å‘å®æˆ˜çš„ AI åº”ç”¨å¼€å‘è·¯å¾„
> 
> æ€»æ—¶é•¿ï¼š2-3 ä¸ªæœˆå³å¯ä¸Šæ‰‹ï¼Œ6 ä¸ªæœˆè¾¾åˆ°ç†Ÿç»ƒ

---

## ğŸ“‹ ç›®å½•

- [å­¦ä¹ è·¯å¾„æ€»è§ˆ](#å­¦ä¹ è·¯å¾„æ€»è§ˆ)
- [æ ¸å¿ƒæŠ€èƒ½æ ‘](#æ ¸å¿ƒæŠ€èƒ½æ ‘)
- [ç¬¬ 1 é˜¶æ®µï¼šLLM åº”ç”¨åŸºç¡€](#ç¬¬-1-é˜¶æ®µllm-åº”ç”¨åŸºç¡€2-3-å‘¨)
- [ç¬¬ 2 é˜¶æ®µï¼šLangChain å®æˆ˜](#ç¬¬-2-é˜¶æ®µlangchain-å®æˆ˜2-3-å‘¨)
- [ç¬¬ 3 é˜¶æ®µï¼šPrompt Engineering](#ç¬¬-3-é˜¶æ®µprompt-engineering1-2-å‘¨)
- [ç¬¬ 4 é˜¶æ®µï¼šRAG æ£€ç´¢å¢å¼º](#ç¬¬-4-é˜¶æ®µrag-æ£€ç´¢å¢å¼º2-3-å‘¨)
- [ç¬¬ 5 é˜¶æ®µï¼šæ¨¡å‹å¾®è°ƒ](#ç¬¬-5-é˜¶æ®µæ¨¡å‹å¾®è°ƒå¯é€‰2-3-å‘¨)
- [ç¬¬ 6 é˜¶æ®µï¼šéƒ¨ç½²ä¸ä¼˜åŒ–](#ç¬¬-6-é˜¶æ®µéƒ¨ç½²ä¸ä¼˜åŒ–1-2-å‘¨)
- [å®æˆ˜é¡¹ç›®](#å®æˆ˜é¡¹ç›®)
- [å­¦ä¹ æ—¶é—´è§„åˆ’](#å­¦ä¹ æ—¶é—´è§„åˆ’)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## å­¦ä¹ è·¯å¾„æ€»è§ˆ

```
ç¬¬ 1 é˜¶æ®µï¼šLLM åº”ç”¨åŸºç¡€ï¼ˆ2-3 å‘¨ï¼‰
  â†“
ç¬¬ 2 é˜¶æ®µï¼šLangChain å®æˆ˜ï¼ˆ2-3 å‘¨ï¼‰
  â†“
ç¬¬ 3 é˜¶æ®µï¼šPrompt Engineeringï¼ˆ1-2 å‘¨ï¼‰
  â†“
ç¬¬ 4 é˜¶æ®µï¼šRAG æ£€ç´¢å¢å¼ºï¼ˆ2-3 å‘¨ï¼‰
  â†“
ç¬¬ 5 é˜¶æ®µï¼šæ¨¡å‹å¾®è°ƒï¼ˆå¯é€‰ï¼Œ2-3 å‘¨ï¼‰
  â†“
ç¬¬ 6 é˜¶æ®µï¼šéƒ¨ç½²ä¸ä¼˜åŒ–ï¼ˆ1-2 å‘¨ï¼‰
```

**æ ¸å¿ƒç†å¿µ**ï¼šè¾¹å­¦è¾¹åšï¼Œå¿«é€Ÿè¿­ä»£ï¼ŒæŒ‰éœ€æ·±å…¥

---

## æ ¸å¿ƒæŠ€èƒ½æ ‘

```
ä¼ä¸šçº§ AI å¼€å‘æŠ€èƒ½æ ‘
â”œâ”€â”€ ğŸ¯ æ ¸å¿ƒæŠ€èƒ½ï¼ˆå¿…ä¿®ï¼‰
â”‚   â”œâ”€â”€ LLM API è°ƒç”¨ â­â­â­â­â­
â”‚   â”œâ”€â”€ LangChain æ¡†æ¶ â­â­â­â­â­
â”‚   â”œâ”€â”€ Prompt Engineering â­â­â­â­â­
â”‚   â””â”€â”€ Agent å¼€å‘ â­â­â­â­â­
â”‚
â”œâ”€â”€ ğŸ”§ è¿›é˜¶æŠ€èƒ½ï¼ˆæ¨èï¼‰
â”‚   â”œâ”€â”€ RAG æ£€ç´¢å¢å¼º â­â­â­â­
â”‚   â”œâ”€â”€ å‘é‡æ•°æ®åº“ â­â­â­â­
â”‚   â”œâ”€â”€ æ¨¡å‹å¾®è°ƒï¼ˆLoRAï¼‰â­â­â­
â”‚   â””â”€â”€ FastAPI éƒ¨ç½² â­â­â­â­
â”‚
â””â”€â”€ ğŸš€ ä¼˜åŒ–æŠ€èƒ½ï¼ˆå¯é€‰ï¼‰
    â”œâ”€â”€ æ€§èƒ½ä¼˜åŒ– â­â­â­
    â”œâ”€â”€ æˆæœ¬ä¼˜åŒ– â­â­â­
    â””â”€â”€ ç›‘æ§å’Œæ—¥å¿— â­â­â­
```

---

## ç¬¬ 1 é˜¶æ®µï¼šLLM åº”ç”¨åŸºç¡€ï¼ˆ2-3 å‘¨ï¼‰

### å­¦ä¹ ç›®æ ‡

- ç†è§£å¤§è¯­è¨€æ¨¡å‹çš„åŸºæœ¬æ¦‚å¿µ
- èƒ½å¤Ÿè°ƒç”¨å„ç§ LLM API
- ç†è§£ Tokenã€Temperatureã€Top-p ç­‰å‚æ•°
- èƒ½å¤Ÿå¤„ç† LLM çš„è¾“å…¥è¾“å‡º

### æ ¸å¿ƒçŸ¥è¯†ç‚¹

#### 1. LLM åŸºç¡€æ¦‚å¿µ

**å¿…é¡»ç†è§£çš„æ¦‚å¿µ**
- Token å’Œ Tokenization
- Context Windowï¼ˆä¸Šä¸‹æ–‡çª—å£ï¼‰
- Temperatureï¼ˆæ¸©åº¦å‚æ•°ï¼‰
- Top-p / Top-k é‡‡æ ·
- System Prompt vs User Prompt

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| OpenAI API å®˜æ–¹æ–‡æ¡£ | æ–‡æ¡£ | è‹±æ–‡ | â­â­â­â­â­ | https://platform.openai.com/docs/introduction |
| å¤§æ¨¡å‹åŸºç¡€æ¦‚å¿µå…¥é—¨ | è§†é¢‘ | ä¸­æ–‡ | â­â­â­â­â­ | https://www.bilibili.com/video/BV1bx4y1Q7rX |
| å¤§è¯­è¨€æ¨¡å‹åŸç†ä¸åº”ç”¨ | æ–‡ç«  | ä¸­æ–‡ | â­â­â­â­ | https://zhuanlan.zhihu.com/p/597586623 |

#### 2. API è°ƒç”¨å®æˆ˜

**OpenAI API**

```python
from openai import OpenAI

client = OpenAI(api_key="your-api-key")

response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"},
        {"role": "user", "content": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"}
    ],
    temperature=0.7,
    max_tokens=500
)

print(response.choices[0].message.content)
```

**å›½äº§å¤§æ¨¡å‹ API**

```python
# Qwen APIï¼ˆå…¼å®¹ OpenAI æ ¼å¼ï¼‰
from openai import OpenAI

client = OpenAI(
    api_key="your-qwen-api-key",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# ä½¿ç”¨æ–¹å¼ä¸ OpenAI ç›¸åŒ
```

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| OpenAI Python SDK | æ–‡æ¡£ | è‹±æ–‡ | â­â­â­â­â­ | https://github.com/openai/openai-python |
| é€šä¹‰åƒé—® API æ–‡æ¡£ | æ–‡æ¡£ | ä¸­æ–‡ | â­â­â­â­â­ | https://help.aliyun.com/zh/dashscope/ |
| æ™ºè°± AI API æ–‡æ¡£ | æ–‡æ¡£ | ä¸­æ–‡ | â­â­â­â­ | https://open.bigmodel.cn/dev/api |
| ç™¾åº¦æ–‡å¿ƒä¸€è¨€ API | æ–‡æ¡£ | ä¸­æ–‡ | â­â­â­â­ | https://cloud.baidu.com/doc/WENXINWORKSHOP/index.html |

#### 3. æµå¼è¾“å‡ºå¤„ç†

```python
# æµå¼è¾“å‡ºï¼ˆæ‰“å­—æœºæ•ˆæœï¼‰
stream = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "è®²ä¸€ä¸ªæ•…äº‹"}],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

### å®æˆ˜ç»ƒä¹ 

1. **åŸºç¡€å¯¹è¯æœºå™¨äºº**ï¼šå®ç°ä¸€ä¸ªç®€å•çš„å‘½ä»¤è¡ŒèŠå¤©ç¨‹åº
2. **å‚æ•°å®éªŒ**ï¼šæµ‹è¯•ä¸åŒ Temperature å¯¹è¾“å‡ºçš„å½±å“
3. **å¤šè½®å¯¹è¯**ï¼šå®ç°å¸¦å†å²è®°å½•çš„å¯¹è¯ç³»ç»Ÿ
4. **æµå¼è¾“å‡º**ï¼šå®ç°æ‰“å­—æœºæ•ˆæœçš„è¾“å‡º

### æ£€éªŒæ ‡å‡†

- âœ… èƒ½å¤Ÿè°ƒç”¨è‡³å°‘ 2 ç§ LLM API
- âœ… ç†è§£å¹¶èƒ½è°ƒæ•´æ¨¡å‹å‚æ•°
- âœ… èƒ½å¤Ÿå¤„ç†æµå¼è¾“å‡º
- âœ… èƒ½å¤Ÿå®ç°å¤šè½®å¯¹è¯

---

## ç¬¬ 2 é˜¶æ®µï¼šLangChain å®æˆ˜ï¼ˆ2-3 å‘¨ï¼‰

### å­¦ä¹ ç›®æ ‡

- æŒæ¡ LangChain æ ¸å¿ƒç»„ä»¶
- èƒ½å¤Ÿæ„å»º Chain å’Œ Agent
- èƒ½å¤Ÿå®šä¹‰å’Œä½¿ç”¨ Tool
- ç†è§£ Memory ç®¡ç†

### æ ¸å¿ƒçŸ¥è¯†ç‚¹

#### 1. LangChain åŸºç¡€ç»„ä»¶

**æ ¸å¿ƒç»„ä»¶**
- LLM Wrapperï¼ˆæ¨¡å‹å°è£…ï¼‰
- Prompt Templateï¼ˆæç¤ºè¯æ¨¡æ¿ï¼‰
- Output Parserï¼ˆè¾“å‡ºè§£æï¼‰
- Chainï¼ˆé“¾å¼è°ƒç”¨ï¼‰

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| LangChain ä¸­æ–‡å…¥é—¨æ•™ç¨‹ | æ•™ç¨‹ | ä¸­æ–‡ | â­â­â­â­â­ | https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide |
| LangChain å®˜æ–¹æ–‡æ¡£ | æ–‡æ¡£ | è‹±æ–‡ | â­â­â­â­â­ | https://python.langchain.com/docs/get_started/introduction |
| LangChain ä¸­æ–‡æ–‡æ¡£ | æ–‡æ¡£ | ä¸­æ–‡ | â­â­â­â­ | https://python.langchain.com.cn/ |
| LangChain å®æˆ˜æ•™ç¨‹ | è§†é¢‘ | ä¸­æ–‡ | â­â­â­â­ | https://www.bilibili.com/video/BV1sN4y1J7bP |

#### 2. Prompt Template

```python
from langchain_core.prompts import ChatPromptTemplate

# åˆ›å»ºæç¤ºè¯æ¨¡æ¿
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ª{role}"),
    ("user", "{input}")
])

# ä½¿ç”¨æ¨¡æ¿
messages = prompt.format_messages(
    role="Python ä¸“å®¶",
    input="å¦‚ä½•è¯»å– CSV æ–‡ä»¶ï¼Ÿ"
)
```

#### 3. Chain é“¾å¼è°ƒç”¨

```python
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# æ„å»ºé“¾
llm = ChatOpenAI(model="gpt-3.5-turbo")
chain = prompt | llm | StrOutputParser()

# æ‰§è¡Œ
result = chain.invoke({
    "role": "Python ä¸“å®¶",
    "input": "å¦‚ä½•è¯»å– CSV æ–‡ä»¶ï¼Ÿ"
})
```

#### 4. Tool å·¥å…·å®šä¹‰

```python
from langchain.tools import tool

@tool
def get_weather(city: str) -> str:
    """è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯"""
    # å®é™…è°ƒç”¨å¤©æ°” API
    return f"{city}çš„å¤©æ°”æ˜¯æ™´å¤©ï¼Œæ¸©åº¦ 25Â°C"

@tool
def search_database(query: str) -> str:
    """åœ¨æ•°æ®åº“ä¸­æœç´¢ä¿¡æ¯"""
    # å®é™…æŸ¥è¯¢æ•°æ®åº“
    return f"æŸ¥è¯¢ç»“æœï¼š{query}"
```

#### 5. Agent å¼€å‘

```python
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate

# å®šä¹‰å·¥å…·åˆ—è¡¨
tools = [get_weather, search_database]

# åˆ›å»ºæç¤ºè¯
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
    ("placeholder", "{chat_history}"),
    ("human", "{input}"),
    ("placeholder", "{agent_scratchpad}"),
])

# åˆ›å»º Agent
agent = create_tool_calling_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

# æ‰§è¡Œ
result = agent_executor.invoke({
    "input": "åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
})
```

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| LangChain Agent æ•™ç¨‹ | æ•™ç¨‹ | ä¸­æ–‡ | â­â­â­â­â­ | https://python.langchain.com.cn/docs/modules/agents/ |
| LangChain Agent å¼€å‘ | è§†é¢‘ | ä¸­æ–‡ | â­â­â­â­ | https://www.bilibili.com/video/BV1TM4y1W7TT |
| LangChain Cookbook | ç¤ºä¾‹ | è‹±æ–‡ | â­â­â­â­â­ | https://github.com/langchain-ai/langchain/tree/master/cookbook |

#### 6. Memory ç®¡ç†

```python
from langchain.memory import ConversationBufferMemory

# åˆ›å»ºè®°å¿†
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

# ä½¿ç”¨è®°å¿†
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    memory=memory,
    verbose=True
)
```

### å®æˆ˜ç»ƒä¹ 

1. **ç®€å• Chain**ï¼šå®ç°ä¸€ä¸ªç¿»è¯‘ Chain
2. **å·¥å…·è°ƒç”¨**ï¼šå®ç° 3-5 ä¸ªè‡ªå®šä¹‰å·¥å…·
3. **Agent å¼€å‘**ï¼šæ„å»ºä¸€ä¸ªèƒ½è°ƒç”¨å·¥å…·çš„ Agent
4. **å¤šè½®å¯¹è¯**ï¼šå®ç°å¸¦è®°å¿†çš„å¯¹è¯ç³»ç»Ÿ

### æ£€éªŒæ ‡å‡†

- âœ… èƒ½å¤Ÿä½¿ç”¨ Prompt Template
- âœ… èƒ½å¤Ÿæ„å»º Chain
- âœ… èƒ½å¤Ÿå®šä¹‰è‡ªå®šä¹‰ Tool
- âœ… èƒ½å¤Ÿå¼€å‘ Agent
- âœ… èƒ½å¤Ÿç®¡ç†å¯¹è¯å†å²

---

## ç¬¬ 3 é˜¶æ®µï¼šPrompt Engineeringï¼ˆ1-2 å‘¨ï¼‰

### å­¦ä¹ ç›®æ ‡

- æŒæ¡æç¤ºè¯è®¾è®¡åŸåˆ™
- èƒ½å¤Ÿä¼˜åŒ–æç¤ºè¯æå‡æ•ˆæœ
- ç†è§£å„ç§æç¤ºæŠ€å·§
- èƒ½å¤Ÿè®¾è®¡å¤æ‚ä»»åŠ¡çš„æç¤ºè¯

### æ ¸å¿ƒçŸ¥è¯†ç‚¹

#### 1. æç¤ºè¯è®¾è®¡åŸåˆ™

**åŸºæœ¬åŸåˆ™**
- æ¸…æ™°æ˜ç¡®ï¼ˆBe Clear and Specificï¼‰
- æä¾›ä¸Šä¸‹æ–‡ï¼ˆProvide Contextï¼‰
- ç»™å‡ºç¤ºä¾‹ï¼ˆUse Examplesï¼‰
- åˆ†æ­¥éª¤ï¼ˆStep by Stepï¼‰
- è®¾å®šè§’è‰²ï¼ˆRole Playingï¼‰

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| æç¤ºå·¥ç¨‹æŒ‡å—ï¼ˆä¸­æ–‡ï¼‰ | æ–‡æ¡£ | ä¸­æ–‡ | â­â­â­â­â­ | https://www.promptingguide.ai/zh |
| LangGPT ç»“æ„åŒ–æç¤ºè¯ | æ•™ç¨‹ | ä¸­æ–‡ | â­â­â­â­â­ | https://github.com/yzfly/LangGPT |
| å´æ©è¾¾ Prompt Engineering è¯¾ç¨‹ | è§†é¢‘ | ä¸­æ–‡å­—å¹• | â­â­â­â­â­ | https://www.bilibili.com/video/BV1Bo4y1A7FU |
| OpenAI Prompt æœ€ä½³å®è·µ | æ–‡æ¡£ | è‹±æ–‡ | â­â­â­â­â­ | https://platform.openai.com/docs/guides/prompt-engineering |
| Prompt æç¤ºè¯æŠ€å·§ | æ–‡ç«  | ä¸­æ–‡ | â­â­â­â­ | https://zhuanlan.zhihu.com/p/632369186 |

#### 2. åŸºç¡€æç¤ºæŠ€å·§

**Zero-shot Prompting**

```python
prompt = """
è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿï¼ˆç§¯æ/æ¶ˆæ/ä¸­æ€§ï¼‰ï¼š

æ–‡æœ¬ï¼šä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œå¿ƒæƒ…å¾ˆæ„‰å¿«ã€‚

æƒ…æ„Ÿï¼š
"""
```

**Few-shot Prompting**

```python
prompt = """
è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿï¼š

ç¤ºä¾‹ 1ï¼š
æ–‡æœ¬ï¼šä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œå¿ƒæƒ…å¾ˆæ„‰å¿«ã€‚
æƒ…æ„Ÿï¼šç§¯æ

ç¤ºä¾‹ 2ï¼š
æ–‡æœ¬ï¼šä¸‹é›¨äº†ï¼Œå¿ƒæƒ…æœ‰ç‚¹ä½è½ã€‚
æƒ…æ„Ÿï¼šæ¶ˆæ

ç¤ºä¾‹ 3ï¼š
æ–‡æœ¬ï¼šä»Šå¤©æ˜¯å‘¨ä¸€ã€‚
æƒ…æ„Ÿï¼šä¸­æ€§

ç°åœ¨åˆ†æï¼š
æ–‡æœ¬ï¼šè¿™ä¸ªäº§å“è´¨é‡å¾ˆä¸é”™ï¼Œå€¼å¾—æ¨èã€‚
æƒ…æ„Ÿï¼š
"""
```

**Chain-of-Thoughtï¼ˆæ€ç»´é“¾ï¼‰**

```python
prompt = """
é—®é¢˜ï¼šä¸€ä¸ªç­çº§æœ‰ 30 ä¸ªå­¦ç”Ÿï¼Œå…¶ä¸­ 60% æ˜¯å¥³ç”Ÿã€‚å¦‚æœæ–°æ¥äº† 5 ä¸ªç”·ç”Ÿï¼Œç°åœ¨å¥³ç”Ÿå æ¯”æ˜¯å¤šå°‘ï¼Ÿ

è¯·ä¸€æ­¥æ­¥æ€è€ƒï¼š
1. é¦–å…ˆè®¡ç®—åŸæ¥æœ‰å¤šå°‘å¥³ç”Ÿ
2. ç„¶åè®¡ç®—åŸæ¥æœ‰å¤šå°‘ç”·ç”Ÿ
3. è®¡ç®—æ–°æ¥ç”·ç”Ÿåçš„æ€»äººæ•°
4. æœ€åè®¡ç®—æ–°çš„å¥³ç”Ÿå æ¯”

è®©æˆ‘ä»¬å¼€å§‹ï¼š
"""
```

#### 3. é«˜çº§æç¤ºæŠ€å·§

**è§’è‰²è®¾å®š**

```python
system_prompt = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ Python å·¥ç¨‹å¸ˆï¼Œæ‹¥æœ‰ 10 å¹´çš„å¼€å‘ç»éªŒã€‚
ä½ æ“…é•¿ï¼š
- ç¼–å†™é«˜è´¨é‡ã€å¯ç»´æŠ¤çš„ä»£ç 
- æ€§èƒ½ä¼˜åŒ–
- æœ€ä½³å®è·µ

ä½ çš„å›ç­”é£æ ¼ï¼š
- ç®€æ´æ˜äº†
- æä¾›ä»£ç ç¤ºä¾‹
- è§£é‡Šå…³é”®æ¦‚å¿µ
"""
```

**ç»“æ„åŒ–è¾“å‡º**

```python
prompt = """
è¯·åˆ†æä»¥ä¸‹äº§å“è¯„è®ºï¼Œå¹¶ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š

è¯„è®ºï¼šè¿™ä¸ªæ‰‹æœºæ‹ç…§æ•ˆæœå¾ˆå¥½ï¼Œä½†æ˜¯ç”µæ± ç»­èˆªä¸€èˆ¬ã€‚

è¾“å‡ºæ ¼å¼ï¼š
{
    "sentiment": "ç§¯æ/æ¶ˆæ/ä¸­æ€§",
    "positive_aspects": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2"],
    "negative_aspects": ["ç¼ºç‚¹1", "ç¼ºç‚¹2"],
    "rating": 1-5
}
"""
```

**ReActï¼ˆæ¨ç†+è¡ŒåŠ¨ï¼‰**

```python
prompt = """
ä½ éœ€è¦å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
- search_database: æœç´¢æ•°æ®åº“
- calculate: æ‰§è¡Œè®¡ç®—
- get_weather: è·å–å¤©æ°”

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ€è€ƒå’Œè¡ŒåŠ¨ï¼š

Thought: æˆ‘éœ€è¦åšä»€ä¹ˆï¼Ÿ
Action: ä½¿ç”¨å“ªä¸ªå·¥å…·
Action Input: å·¥å…·çš„è¾“å…¥
Observation: å·¥å…·çš„è¾“å‡º
... (é‡å¤ Thought/Action/Observation)
Thought: æˆ‘ç°åœ¨çŸ¥é“ç­”æ¡ˆäº†
Final Answer: æœ€ç»ˆç­”æ¡ˆ

é—®é¢˜ï¼šåŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ
"""
```

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| Chain-of-Thought è®ºæ–‡è§£è¯» | æ–‡ç«  | ä¸­æ–‡ | â­â­â­â­ | https://zhuanlan.zhihu.com/p/589087074 |
| ReAct æç¤ºæŠ€å·§ | æ•™ç¨‹ | ä¸­æ–‡ | â­â­â­â­ | https://www.promptingguide.ai/zh/techniques/react |
| Prompt Engineering å®æˆ˜ | è§†é¢‘ | ä¸­æ–‡ | â­â­â­â­ | https://www.bilibili.com/video/BV1No4y1t7Zn |

### å®æˆ˜ç»ƒä¹ 

1. **æƒ…æ„Ÿåˆ†æ**ï¼šè®¾è®¡æç¤ºè¯è¿›è¡Œæ–‡æœ¬æƒ…æ„Ÿåˆ†æ
2. **æ•°æ®æå–**ï¼šä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯
3. **ä»£ç ç”Ÿæˆ**ï¼šè®¾è®¡æç¤ºè¯ç”Ÿæˆé«˜è´¨é‡ä»£ç 
4. **å¤æ‚æ¨ç†**ï¼šä½¿ç”¨ CoT è§£å†³æ•°å­¦æˆ–é€»è¾‘é—®é¢˜

### æ£€éªŒæ ‡å‡†

- âœ… èƒ½å¤Ÿè®¾è®¡æ¸…æ™°æœ‰æ•ˆçš„æç¤ºè¯
- âœ… èƒ½å¤Ÿä½¿ç”¨ Few-shot æå‡æ•ˆæœ
- âœ… èƒ½å¤Ÿä½¿ç”¨ CoT å¤„ç†å¤æ‚ä»»åŠ¡
- âœ… èƒ½å¤Ÿè®¾è®¡ç»“æ„åŒ–è¾“å‡º
- âœ… èƒ½å¤Ÿä¼˜åŒ–æç¤ºè¯é™ä½æˆæœ¬

---

## ç¬¬ 4 é˜¶æ®µï¼šRAG æ£€ç´¢å¢å¼ºï¼ˆ2-3 å‘¨ï¼‰

### å­¦ä¹ ç›®æ ‡

- ç†è§£ RAG çš„åŸç†å’Œåº”ç”¨åœºæ™¯
- æŒæ¡å‘é‡æ•°æ®åº“çš„ä½¿ç”¨
- èƒ½å¤Ÿæ„å»ºæ–‡æ¡£é—®ç­”ç³»ç»Ÿ
- èƒ½å¤Ÿä¼˜åŒ–æ£€ç´¢æ•ˆæœ

### æ ¸å¿ƒçŸ¥è¯†ç‚¹

#### 1. RAG åŸºç¡€æ¦‚å¿µ

**ä»€ä¹ˆæ˜¯ RAGï¼Ÿ**
- Retrievalï¼ˆæ£€ç´¢ï¼‰ï¼šä»çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³æ–‡æ¡£
- Augmentedï¼ˆå¢å¼ºï¼‰ï¼šå°†æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡
- Generationï¼ˆç”Ÿæˆï¼‰ï¼šLLM åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ

**ä¸ºä»€ä¹ˆéœ€è¦ RAGï¼Ÿ**
- è§£å†³ LLM çŸ¥è¯†è¿‡æ—¶é—®é¢˜
- æä¾›å¯è¿½æº¯çš„ä¿¡æ¯æ¥æº
- é™ä½å¹»è§‰ï¼ˆHallucinationï¼‰
- æ”¯æŒç§æœ‰çŸ¥è¯†åº“

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| RAG ä»å…¥é—¨åˆ°ç²¾é€š | æ•™ç¨‹ | ä¸­æ–‡ | â­â­â­â­â­ | https://github.com/NirDiamant/RAG_Techniques |
| RAG åŸç†è¯¦è§£ | æ–‡ç«  | ä¸­æ–‡ | â­â­â­â­â­ | https://zhuanlan.zhihu.com/p/647392838 |
| LangChain RAG æ•™ç¨‹ | æ•™ç¨‹ | ä¸­æ–‡ | â­â­â­â­ | https://python.langchain.com.cn/docs/use_cases/question_answering/ |
| RAG æ£€ç´¢å¢å¼ºç”Ÿæˆå®æˆ˜ | è§†é¢‘ | ä¸­æ–‡ | â­â­â­â­ | https://www.bilibili.com/video/BV1w8411B7jK |

#### 2. å‘é‡æ•°æ®åº“

**Embeddingï¼ˆå‘é‡åŒ–ï¼‰**

```python
from langchain_openai import OpenAIEmbeddings

# åˆ›å»º Embedding æ¨¡å‹
embeddings = OpenAIEmbeddings()

# å‘é‡åŒ–æ–‡æœ¬
text = "ä»Šå¤©å¤©æ°”å¾ˆå¥½"
vector = embeddings.embed_query(text)

print(f"å‘é‡ç»´åº¦: {len(vector)}")  # 1536
print(f"å‘é‡å‰ 5 ä¸ªå€¼: {vector[:5]}")
```

**Chroma å‘é‡æ•°æ®åº“**

```python
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# 1. åŠ è½½æ–‡æ¡£
loader = TextLoader("document.txt")
documents = loader.load()

# 2. åˆ‡åˆ†æ–‡æ¡£
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)
chunks = text_splitter.split_documents(documents)

# 3. åˆ›å»ºå‘é‡æ•°æ®åº“
vectorstore = Chroma.from_documents(
    documents=chunks,
    embedding=embeddings,
    persist_directory="./chroma_db"
)

# 4. æ£€ç´¢
results = vectorstore.similarity_search("æŸ¥è¯¢é—®é¢˜", k=3)
```

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| Chroma å®˜æ–¹æ–‡æ¡£ | æ–‡æ¡£ | è‹±æ–‡ | â­â­â­â­â­ | https://docs.trychroma.com/ |
| å‘é‡æ•°æ®åº“å¯¹æ¯” | æ–‡ç«  | ä¸­æ–‡ | â­â­â­â­ | https://zhuanlan.zhihu.com/p/647392838 |
| å‘é‡æ•°æ®åº“ä¸ Embedding | è§†é¢‘ | ä¸­æ–‡ | â­â­â­â­ | https://www.bilibili.com/video/BV1Qu4y1h7gx |
| Qdrant å®˜æ–¹æ–‡æ¡£ | æ–‡æ¡£ | è‹±æ–‡ | â­â­â­â­ | https://qdrant.tech/documentation/ |

#### 3. æ„å»º RAG ç³»ç»Ÿ

**åŸºç¡€ RAG**

```python
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI

# åˆ›å»ºæ£€ç´¢å™¨
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# åˆ›å»º QA Chain
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-3.5-turbo"),
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)

# æé—®
result = qa_chain.invoke({"query": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"})
print(result["result"])
print(result["source_documents"])
```

**è‡ªå®šä¹‰ RAG**

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# è‡ªå®šä¹‰æç¤ºè¯
template = """
åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´"æˆ‘ä¸çŸ¥é“"ã€‚

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{question}

ç­”æ¡ˆï¼š
"""

prompt = ChatPromptTemplate.from_template(template)

# æ„å»º RAG Chain
def format_docs(docs):
    return "\n\n".join([d.page_content for d in docs])

rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# ä½¿ç”¨
answer = rag_chain.invoke("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")
```

#### 4. RAG ä¼˜åŒ–æŠ€å·§

**æ–‡æ¡£åˆ‡åˆ†ç­–ç•¥**

```python
# æŒ‰å­—ç¬¦åˆ‡åˆ†
from langchain_text_splitters import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,      # å—å¤§å°
    chunk_overlap=50,    # é‡å éƒ¨åˆ†
    separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", " ", ""]
)

# æŒ‰è¯­ä¹‰åˆ‡åˆ†
from langchain_experimental.text_splitter import SemanticChunker

splitter = SemanticChunker(embeddings)
```

**æ··åˆæ£€ç´¢ï¼ˆBM25 + Vectorï¼‰**

```python
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever

# BM25 æ£€ç´¢å™¨ï¼ˆå…³é”®è¯ï¼‰
bm25_retriever = BM25Retriever.from_documents(documents)
bm25_retriever.k = 3

# å‘é‡æ£€ç´¢å™¨ï¼ˆè¯­ä¹‰ï¼‰
vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# æ··åˆæ£€ç´¢å™¨
ensemble_retriever = EnsembleRetriever(
    retrievers=[bm25_retriever, vector_retriever],
    weights=[0.4, 0.6]  # BM25 å  40%ï¼Œå‘é‡å  60%
)
```

**é‡æ’åºï¼ˆRerankingï¼‰**

```python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import CohereRerank

# åˆ›å»ºé‡æ’åºå™¨
compressor = CohereRerank()

# åˆ›å»ºå‹ç¼©æ£€ç´¢å™¨
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=retriever
)
```

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| RAG ä¼˜åŒ–æŠ€å·§ | æ–‡ç«  | ä¸­æ–‡ | â­â­â­â­â­ | https://zhuanlan.zhihu.com/p/670925591 |
| æ··åˆæ£€ç´¢å®æˆ˜ | æ•™ç¨‹ | ä¸­æ–‡ | â­â­â­â­ | https://python.langchain.com.cn/docs/modules/data_connection/retrievers/ensemble |
| Advanced RAG | åšå®¢ | è‹±æ–‡ | â­â­â­â­â­ | https://blog.llamaindex.ai/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6 |

### å®æˆ˜ç»ƒä¹ 

1. **æ–‡æ¡£é—®ç­”**ï¼šæ„å»ºä¸€ä¸ªä¼ä¸šæ–‡æ¡£é—®ç­”ç³»ç»Ÿ
2. **æ£€ç´¢ä¼˜åŒ–**ï¼šå®ç°æ··åˆæ£€ç´¢å¹¶å¯¹æ¯”æ•ˆæœ
3. **å¤šæ–‡æ¡£æº**ï¼šæ•´åˆå¤šä¸ªæ–‡æ¡£æºçš„ RAG ç³»ç»Ÿ
4. **å¼•ç”¨æ¥æº**ï¼šå®ç°å¸¦å¼•ç”¨æ¥æºçš„å›ç­”

### æ£€éªŒæ ‡å‡†

- âœ… èƒ½å¤Ÿä½¿ç”¨å‘é‡æ•°æ®åº“
- âœ… èƒ½å¤Ÿæ„å»ºåŸºç¡€ RAG ç³»ç»Ÿ
- âœ… èƒ½å¤Ÿä¼˜åŒ–æ–‡æ¡£åˆ‡åˆ†ç­–ç•¥
- âœ… èƒ½å¤Ÿå®ç°æ··åˆæ£€ç´¢
- âœ… èƒ½å¤Ÿè¯„ä¼°æ£€ç´¢æ•ˆæœ

---

## ç¬¬ 5 é˜¶æ®µï¼šæ¨¡å‹å¾®è°ƒï¼ˆå¯é€‰ï¼Œ2-3 å‘¨ï¼‰

### å­¦ä¹ ç›®æ ‡

- ç†è§£ä½•æ—¶éœ€è¦å¾®è°ƒ
- æŒæ¡ LoRA å¾®è°ƒæ–¹æ³•
- èƒ½å¤Ÿä½¿ç”¨ LLaMA-Factory å¾®è°ƒ
- èƒ½å¤Ÿè¯„ä¼°å¾®è°ƒæ•ˆæœ

### æ ¸å¿ƒçŸ¥è¯†ç‚¹

#### 1. ä½•æ—¶éœ€è¦å¾®è°ƒï¼Ÿ

**éœ€è¦å¾®è°ƒçš„åœºæ™¯**
- é€šç”¨æ¨¡å‹æ•ˆæœä¸å¤Ÿå¥½
- æœ‰å¤§é‡é¢†åŸŸä¸“ä¸šæœ¯è¯­
- éœ€è¦ç‰¹å®šçš„è¾“å‡ºæ ¼å¼
- éœ€è¦å›ºåŒ–æŸäº›è¡Œä¸ºæ¨¡å¼

**ä¸éœ€è¦å¾®è°ƒçš„åœºæ™¯**
- Prompt Engineering å°±èƒ½è§£å†³
- æ•°æ®é‡å¤ªå°‘ï¼ˆ< 500 æ¡ï¼‰
- é¢„ç®—å’Œæ—¶é—´æœ‰é™
- çŸ¥è¯†é¢‘ç¹æ›´æ–°

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| å¤§æ¨¡å‹å¾®è°ƒå®æˆ˜ | æ•™ç¨‹ | ä¸­æ–‡ | â­â­â­â­â­ | https://github.com/datawhalechina/self-llm |
| LoRA åŸç†è¯¦è§£ | æ–‡ç«  | ä¸­æ–‡ | â­â­â­â­â­ | https://zhuanlan.zhihu.com/p/636038478 |
| å¾®è°ƒ vs RAG vs Prompt | å¯¹æ¯” | ä¸­æ–‡ | â­â­â­â­ | https://zhuanlan.zhihu.com/p/647392838 |

#### 2. LLaMA-Factory å¾®è°ƒ

**å®‰è£…å’Œå¯åŠ¨**

```bash
# å®‰è£…
pip install llama-factory

# å¯åŠ¨ Web UI
llamafactory-cli webui
```

**å‡†å¤‡è®­ç»ƒæ•°æ®**

```json
[
  {
    "messages": [
      {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"},
      {"role": "user", "content": "ä»€ä¹ˆæ˜¯çº³ç»Ÿï¼Ÿ"},
      {"role": "assistant", "content": "çº³ç»Ÿæ˜¯æŒ‡çº³å…¥ç»Ÿè®¡å±€ç»Ÿè®¡çš„æŠ•èµ„é‡‘é¢"}
    ]
  },
  {
    "messages": [
      {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"},
      {"role": "user", "content": "æŸ¥è¯¢åœ¨å»ºé¡¹ç›®"},
      {"role": "assistant", "content": "åº”è¯¥è°ƒç”¨ get_dashboard_info å·¥å…·"}
    ]
  }
]
```

**Web UI å¾®è°ƒæ­¥éª¤**
1. é€‰æ‹©æ¨¡å‹ï¼ˆå¦‚ Qwen/Qwen-7Bï¼‰
2. ä¸Šä¼ è®­ç»ƒæ•°æ®
3. é€‰æ‹©å¾®è°ƒæ–¹æ³•ï¼ˆLoRAï¼‰
4. è®¾ç½®å‚æ•°ï¼ˆr=8, lora_alpha=16ï¼‰
5. å¼€å§‹è®­ç»ƒ
6. å¯¼å‡ºæ¨¡å‹

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| LLaMA-Factory ä¸­æ–‡æ–‡æ¡£ | æ–‡æ¡£ | ä¸­æ–‡ | â­â­â­â­â­ | https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md |
| LLaMA-Factory è§†é¢‘æ•™ç¨‹ | è§†é¢‘ | ä¸­æ–‡ | â­â­â­â­â­ | https://www.bilibili.com/video/BV1Qh4y1L7Wd |
| LoRA å¾®è°ƒå®æˆ˜ | æ•™ç¨‹ | ä¸­æ–‡ | â­â­â­â­ | https://zhuanlan.zhihu.com/p/636038478 |

#### 3. ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹

**éƒ¨ç½²ä¸º API æœåŠ¡**

```bash
# ä½¿ç”¨ vLLM éƒ¨ç½²
pip install vllm

python -m vllm.entrypoints.openai.api_server \
    --model ./my_finetuned_model \
    --port 8000
```

**åœ¨ LangChain ä¸­ä½¿ç”¨**

```python
from langchain_openai import ChatOpenAI

# è¿æ¥åˆ°å¾®è°ƒæ¨¡å‹
model = ChatOpenAI(
    base_url="http://localhost:8000/v1",
    api_key="dummy",
    model="my_finetuned_model"
)

# ä½¿ç”¨ï¼ˆå’Œä¹‹å‰ä¸€æ ·ï¼‰
response = model.invoke("æŸ¥è¯¢åœ¨å»ºé¡¹ç›®")
```

### å®æˆ˜ç»ƒä¹ 

1. **æ•°æ®å‡†å¤‡**ï¼šä»å¯¹è¯æ—¥å¿—ç”Ÿæˆè®­ç»ƒæ•°æ®
2. **LoRA å¾®è°ƒ**ï¼šä½¿ç”¨ LLaMA-Factory å¾®è°ƒæ¨¡å‹
3. **æ•ˆæœè¯„ä¼°**ï¼šå¯¹æ¯”å¾®è°ƒå‰åçš„æ•ˆæœ
4. **æ¨¡å‹éƒ¨ç½²**ï¼šéƒ¨ç½²å¾®è°ƒåçš„æ¨¡å‹

### æ£€éªŒæ ‡å‡†

- âœ… èƒ½å¤Ÿå‡†å¤‡è®­ç»ƒæ•°æ®
- âœ… èƒ½å¤Ÿä½¿ç”¨ LLaMA-Factory å¾®è°ƒ
- âœ… èƒ½å¤Ÿè¯„ä¼°å¾®è°ƒæ•ˆæœ
- âœ… èƒ½å¤Ÿéƒ¨ç½²å¾®è°ƒåçš„æ¨¡å‹

---

## ç¬¬ 6 é˜¶æ®µï¼šéƒ¨ç½²ä¸ä¼˜åŒ–ï¼ˆ1-2 å‘¨ï¼‰

### å­¦ä¹ ç›®æ ‡

- èƒ½å¤Ÿéƒ¨ç½² AI åº”ç”¨
- æŒæ¡æ€§èƒ½ä¼˜åŒ–æŠ€å·§
- äº†è§£æˆæœ¬ä¼˜åŒ–æ–¹æ³•
- èƒ½å¤Ÿç›‘æ§å’Œè°ƒè¯•

### æ ¸å¿ƒçŸ¥è¯†ç‚¹

#### 1. FastAPI éƒ¨ç½²

**åˆ›å»º API æœåŠ¡**

```python
from fastapi import FastAPI
from pydantic import BaseModel
from langchain_openai import ChatOpenAI

app = FastAPI()

class ChatRequest(BaseModel):
    message: str

class ChatResponse(BaseModel):
    response: str

llm = ChatOpenAI(model="gpt-3.5-turbo")

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    response = llm.invoke(request.message)
    return ChatResponse(response=response.content)

# è¿è¡Œï¼šuvicorn main:app --host 0.0.0.0 --port 8000
```

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| FastAPI ä¸­æ–‡æ•™ç¨‹ | æ–‡æ¡£ | ä¸­æ–‡ | â­â­â­â­â­ | https://fastapi.tiangolo.com/zh/ |
| FastAPI å¿«é€Ÿå…¥é—¨ | è§†é¢‘ | ä¸­æ–‡ | â­â­â­â­ | https://www.bilibili.com/video/BV1NL411N7vQ |

#### 2. Docker å®¹å™¨åŒ–

**Dockerfile**

```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**docker-compose.yml**

```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./data:/app/data
```

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| Docker ä»å…¥é—¨åˆ°å®è·µ | ä¹¦ç± | ä¸­æ–‡ | â­â­â­â­â­ | https://yeasy.gitbook.io/docker_practice/ |
| Docker å…¥é—¨æ•™ç¨‹ | è§†é¢‘ | ä¸­æ–‡ | â­â­â­â­ | https://www.bilibili.com/video/BV1s54y1n7Ev |

#### 3. æ€§èƒ½ä¼˜åŒ–

**ç¼“å­˜ç­–ç•¥**

```python
from functools import lru_cache
import hashlib

# å†…å­˜ç¼“å­˜
@lru_cache(maxsize=100)
def get_embedding(text: str):
    return embeddings.embed_query(text)

# Redis ç¼“å­˜
import redis
r = redis.Redis(host='localhost', port=6379)

def cached_llm_call(prompt: str):
    # ç”Ÿæˆç¼“å­˜é”®
    cache_key = hashlib.md5(prompt.encode()).hexdigest()
    
    # æ£€æŸ¥ç¼“å­˜
    cached = r.get(cache_key)
    if cached:
        return cached.decode()
    
    # è°ƒç”¨ LLM
    response = llm.invoke(prompt)
    
    # å­˜å…¥ç¼“å­˜
    r.setex(cache_key, 3600, response.content)
    
    return response.content
```

**å¹¶å‘å¤„ç†**

```python
import asyncio
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-3.5-turbo")

async def process_batch(questions):
    tasks = [llm.ainvoke(q) for q in questions]
    results = await asyncio.gather(*tasks)
    return results

# ä½¿ç”¨
questions = ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"]
results = asyncio.run(process_batch(questions))
```

**å­¦ä¹ èµ„æº**

| èµ„æº | ç±»å‹ | è¯­è¨€ | è´¨é‡ | é“¾æ¥ |
|------|------|------|------|------|
| LLM åº”ç”¨æ€§èƒ½ä¼˜åŒ– | æ–‡ç«  | ä¸­æ–‡ | â­â­â­â­ | https://zhuanlan.zhihu.com/p/647392838 |
| ç¼“å­˜ç­–ç•¥è¯¦è§£ | æ•™ç¨‹ | ä¸­æ–‡ | â­â­â­â­ | https://python.langchain.com.cn/docs/modules/model_io/llms/llm_caching |

#### 4. æˆæœ¬ä¼˜åŒ–

**Prompt å‹ç¼©**

```python
# å‡å°‘ä¸å¿…è¦çš„ä¸Šä¸‹æ–‡
def compress_context(context, max_length=1000):
    if len(context) > max_length:
        return context[:max_length] + "..."
    return context

# ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹
cheap_llm = ChatOpenAI(model="gpt-3.5-turbo")  # ä¾¿å®œ
expensive_llm = ChatOpenAI(model="gpt-4")      # è´µ

# ç®€å•ä»»åŠ¡ç”¨ä¾¿å®œæ¨¡å‹
if is_simple_task(question):
    response = cheap_llm.invoke(question)
else:
    response = expensive_llm.invoke(question)
```

**æµå¼è¾“å‡º**

```python
# æµå¼è¾“å‡ºå¯ä»¥æ›´å¿«æ˜¾ç¤ºç»“æœï¼Œæå‡ç”¨æˆ·ä½“éªŒ
for chunk in llm.stream("è®²ä¸€ä¸ªæ•…äº‹"):
    print(chunk.content, end="", flush=True)
```

#### 5. ç›‘æ§å’Œæ—¥å¿—

```python
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# è®°å½•è¯·æ±‚
@app.post("/chat")
async def chat(request: ChatRequest):
    start_time = datetime.now()
    
    try:
        response = llm.invoke(request.message)
        
        # è®°å½•æˆåŠŸ
        logger.info(f"Request: {request.message[:50]}... | "
                   f"Response: {response.content[:50]}... | "
                   f"Time: {(datetime.now() - start_time).total_seconds()}s")
        
        return ChatResponse(response=response.content)
    
    except Exception as e:
        # è®°å½•é”™è¯¯
        logger.error(f"Error: {str(e)} | Request: {request.message}")
        raise
```

### å®æˆ˜ç»ƒä¹ 

1. **API æœåŠ¡**ï¼šéƒ¨ç½²ä¸€ä¸ª FastAPI æœåŠ¡
2. **Docker éƒ¨ç½²**ï¼šå®¹å™¨åŒ–ä½ çš„åº”ç”¨
3. **æ€§èƒ½ä¼˜åŒ–**ï¼šå®ç°ç¼“å­˜å’Œå¹¶å‘
4. **ç›‘æ§æ—¥å¿—**ï¼šæ·»åŠ å®Œæ•´çš„æ—¥å¿—ç³»ç»Ÿ

### æ£€éªŒæ ‡å‡†

- âœ… èƒ½å¤Ÿéƒ¨ç½² FastAPI æœåŠ¡
- âœ… èƒ½å¤Ÿä½¿ç”¨ Docker å®¹å™¨åŒ–
- âœ… èƒ½å¤Ÿå®ç°ç¼“å­˜ä¼˜åŒ–
- âœ… èƒ½å¤Ÿæ·»åŠ ç›‘æ§å’Œæ—¥å¿—

---

## å®æˆ˜é¡¹ç›®

### é¡¹ç›® 1ï¼šæ™ºèƒ½å®¢æœæœºå™¨äººï¼ˆå…¥é—¨ï¼‰

**åŠŸèƒ½éœ€æ±‚**
- å¤šè½®å¯¹è¯
- å¸¸è§é—®é¢˜è§£ç­”
- æƒ…æ„Ÿè¯†åˆ«
- å·¥å•åˆ›å»º

**æŠ€æœ¯æ ˆ**
- LangChain
- Prompt Engineering
- Memory ç®¡ç†

**æ—¶é—´**ï¼š1 å‘¨

---

### é¡¹ç›® 2ï¼šä¼ä¸šçŸ¥è¯†åº“é—®ç­”ï¼ˆè¿›é˜¶ï¼‰

**åŠŸèƒ½éœ€æ±‚**
- æ–‡æ¡£ä¸Šä¼ å’Œç´¢å¼•
- æ™ºèƒ½æ£€ç´¢
- å¼•ç”¨æ¥æº
- å¤šæ–‡æ¡£æºæ•´åˆ

**æŠ€æœ¯æ ˆ**
- RAG
- å‘é‡æ•°æ®åº“ï¼ˆChromaï¼‰
- æ··åˆæ£€ç´¢

**æ—¶é—´**ï¼š2 å‘¨

---

### é¡¹ç›® 3ï¼šä»£ç åŠ©æ‰‹ï¼ˆè¿›é˜¶ï¼‰

**åŠŸèƒ½éœ€æ±‚**
- ä»£ç ç”Ÿæˆ
- ä»£ç è§£é‡Š
- Bug ä¿®å¤
- ä»£ç å®¡æŸ¥

**æŠ€æœ¯æ ˆ**
- LangChain Agent
- Tool è°ƒç”¨
- Prompt Engineering

**æ—¶é—´**ï¼š2 å‘¨

---

### é¡¹ç›® 4ï¼šæ•°æ®åˆ†æåŠ©æ‰‹ï¼ˆç»¼åˆï¼‰

**åŠŸèƒ½éœ€æ±‚**
- è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ•°æ®åº“
- æ•°æ®å¯è§†åŒ–
- æŠ¥å‘Šç”Ÿæˆ
- è¶‹åŠ¿åˆ†æ

**æŠ€æœ¯æ ˆ**
- LangChain Agent
- SQL Tool
- å›¾è¡¨ç”Ÿæˆ
- RAG

**æ—¶é—´**ï¼š3 å‘¨

---

## å­¦ä¹ æ—¶é—´è§„åˆ’

### å…¨èŒå­¦ä¹ ï¼ˆ2-3 ä¸ªæœˆï¼‰

**æ¯å¤© 6-8 å°æ—¶**

| é˜¶æ®µ | æ—¶é—´ | é‡ç‚¹ |
|------|------|------|
| ç¬¬ 1 é˜¶æ®µ | 2-3 å‘¨ | LLM API è°ƒç”¨ |
| ç¬¬ 2 é˜¶æ®µ | 2-3 å‘¨ | LangChain æ¡†æ¶ |
| ç¬¬ 3 é˜¶æ®µ | 1-2 å‘¨ | Prompt Engineering |
| ç¬¬ 4 é˜¶æ®µ | 2-3 å‘¨ | RAG ç³»ç»Ÿ |
| ç¬¬ 5 é˜¶æ®µ | 2-3 å‘¨ï¼ˆå¯é€‰ï¼‰ | æ¨¡å‹å¾®è°ƒ |
| ç¬¬ 6 é˜¶æ®µ | 1-2 å‘¨ | éƒ¨ç½²ä¼˜åŒ– |

**æ€»è®¡**ï¼š10-16 å‘¨ï¼ˆ2.5-4 ä¸ªæœˆï¼‰

---

### ä¸šä½™å­¦ä¹ ï¼ˆ4-6 ä¸ªæœˆï¼‰

**æ¯å¤© 2-3 å°æ—¶**

| é˜¶æ®µ | æ—¶é—´ | é‡ç‚¹ |
|------|------|------|
| ç¬¬ 1 é˜¶æ®µ | 3-4 å‘¨ | LLM API è°ƒç”¨ |
| ç¬¬ 2 é˜¶æ®µ | 4-5 å‘¨ | LangChain æ¡†æ¶ |
| ç¬¬ 3 é˜¶æ®µ | 2-3 å‘¨ | Prompt Engineering |
| ç¬¬ 4 é˜¶æ®µ | 4-5 å‘¨ | RAG ç³»ç»Ÿ |
| ç¬¬ 5 é˜¶æ®µ | 4-5 å‘¨ï¼ˆå¯é€‰ï¼‰ | æ¨¡å‹å¾®è°ƒ |
| ç¬¬ 6 é˜¶æ®µ | 2-3 å‘¨ | éƒ¨ç½²ä¼˜åŒ– |

**æ€»è®¡**ï¼š19-25 å‘¨ï¼ˆ4.5-6 ä¸ªæœˆï¼‰

---

## å¸¸è§é—®é¢˜

### Q1ï¼šéœ€è¦æ·±åº¦å­¦ä¹ åŸºç¡€å—ï¼Ÿ

**ä¸éœ€è¦ï¼** ä¼ä¸šçº§ AI å¼€å‘ä¸»è¦æ˜¯åº”ç”¨å±‚é¢ï¼Œä¸éœ€è¦æ·±å…¥ç†è§£æ·±åº¦å­¦ä¹ åŸç†ã€‚

**éœ€è¦äº†è§£çš„**ï¼š
- LLM çš„åŸºæœ¬æ¦‚å¿µï¼ˆTokenã€Temperature ç­‰ï¼‰
- Embedding çš„ä½œç”¨
- åŸºæœ¬çš„æ¦‚ç‡æ¦‚å¿µ

**ä¸éœ€è¦äº†è§£çš„**ï¼š
- åå‘ä¼ æ’­ç®—æ³•
- æ¢¯åº¦ä¸‹é™æ•°å­¦æ¨å¯¼
- Transformer å†…éƒ¨å®ç°

---

### Q2ï¼šPython éœ€è¦å¤šç†Ÿç»ƒï¼Ÿ

**ä¸­çº§æ°´å¹³å³å¯**

**å¿…é¡»æŒæ¡**ï¼š
- åŸºç¡€è¯­æ³•ï¼ˆå˜é‡ã€å‡½æ•°ã€ç±»ï¼‰
- æ•°æ®ç»“æ„ï¼ˆlistã€dictï¼‰
- æ–‡ä»¶æ“ä½œ
- å¼‚å¸¸å¤„ç†

**æ¨èæŒæ¡**ï¼š
- è£…é¥°å™¨
- å¼‚æ­¥ç¼–ç¨‹ï¼ˆasync/awaitï¼‰
- å¸¸ç”¨åº“ï¼ˆrequestsã€jsonï¼‰

**ä¸éœ€è¦**ï¼š
- å…ƒç¼–ç¨‹
- C æ‰©å±•
- åº•å±‚ä¼˜åŒ–

---

### Q3ï¼šéœ€è¦è´­ä¹° GPU å—ï¼Ÿ

**ä¸éœ€è¦ï¼**

**åŸå› **ï¼š
- ä½¿ç”¨ API è°ƒç”¨æ¨¡å‹ï¼ˆOpenAIã€Qwen ç­‰ï¼‰
- å¾®è°ƒå¯ä»¥ç”¨äº‘æœåŠ¡æˆ– Google Colab
- RAG ä¸éœ€è¦ GPU

**ä»€ä¹ˆæ—¶å€™éœ€è¦ GPU**ï¼š
- æœ¬åœ°éƒ¨ç½²å¤§æ¨¡å‹
- å¤§è§„æ¨¡å¾®è°ƒ
- å®æ—¶æ¨ç†è¦æ±‚æé«˜

---

### Q4ï¼šæˆæœ¬å¤§æ¦‚å¤šå°‘ï¼Ÿ

**å­¦ä¹ é˜¶æ®µ**ï¼š
- API è°ƒç”¨ï¼š$10-50/æœˆ
- äº‘æœåŠ¡å™¨ï¼ˆå¯é€‰ï¼‰ï¼š$20-50/æœˆ
- æ€»è®¡ï¼š$30-100/æœˆ

**ç”Ÿäº§ç¯å¢ƒ**ï¼š
- API è°ƒç”¨ï¼š$100-1000/æœˆï¼ˆå–å†³äºæµé‡ï¼‰
- äº‘æœåŠ¡å™¨ï¼š$50-200/æœˆ
- å‘é‡æ•°æ®åº“ï¼š$0-100/æœˆ
- æ€»è®¡ï¼š$150-1300/æœˆ

---

### Q5ï¼šå¦‚ä½•é€‰æ‹©å­¦ä¹ è·¯å¾„ï¼Ÿ

**å¦‚æœä½ çš„ç›®æ ‡æ˜¯**ï¼š

**å¿«é€Ÿä¸Šæ‰‹ï¼ˆ1-2 ä¸ªæœˆï¼‰**
â†’ åªå­¦ç¬¬ 1-3 é˜¶æ®µ
â†’ é‡ç‚¹ï¼šLangChain + Prompt

**å®Œæ•´æŒæ¡ï¼ˆ2-3 ä¸ªæœˆï¼‰**
â†’ å­¦å®Œç¬¬ 1-4 é˜¶æ®µ
â†’ é‡ç‚¹ï¼šLangChain + RAG

**æ·±å…¥ç²¾é€šï¼ˆ3-4 ä¸ªæœˆï¼‰**
â†’ å­¦å®Œæ‰€æœ‰é˜¶æ®µ
â†’ é‡ç‚¹ï¼šå…¨æ ˆèƒ½åŠ›

---

### Q6ï¼šé‡åˆ°é—®é¢˜æ€ä¹ˆåŠï¼Ÿ

**æ¨èèµ„æº**ï¼š

1. **å®˜æ–¹æ–‡æ¡£**
   - LangChainï¼šhttps://python.langchain.com/
   - OpenAIï¼šhttps://platform.openai.com/docs/

2. **ç¤¾åŒº**
   - GitHub Issues
   - Stack Overflow
   - çŸ¥ä¹
   - Discord/Slack ç¤¾åŒº

3. **å®è·µ**
   - å¤šå†™ä»£ç 
   - å¤šåšé¡¹ç›®
   - å¤šçœ‹åˆ«äººçš„ä»£ç 

---

## å­¦ä¹ å»ºè®®

### 1. è¾¹å­¦è¾¹åš

```
ç†è®ºå­¦ä¹ ï¼š30%
ä»£ç å®è·µï¼š50%
é¡¹ç›®å¼€å‘ï¼š20%
```

**æ¯å­¦ä¸€ä¸ªæ¦‚å¿µï¼Œç«‹å³å†™ä»£ç éªŒè¯ï¼**

---

### 2. ä»ç®€å•å¼€å§‹

```
ç¬¬ 1 å‘¨ï¼šè°ƒç”¨ APIï¼Œå®ç°ç®€å•å¯¹è¯
ç¬¬ 2 å‘¨ï¼šä½¿ç”¨ LangChainï¼Œæ„å»º Chain
ç¬¬ 3 å‘¨ï¼šä¼˜åŒ– Promptï¼Œæå‡æ•ˆæœ
ç¬¬ 4 å‘¨ï¼šæ„å»º RAGï¼Œå®ç°æ–‡æ¡£é—®ç­”
...
```

**ä¸è¦ä¸€å¼€å§‹å°±åšå¤æ‚é¡¹ç›®ï¼**

---

### 3. é‡è§† Prompt

```
å¥½çš„ Prompt > å¤æ‚çš„ä»£ç 
```

**80% çš„é—®é¢˜å¯ä»¥é€šè¿‡ä¼˜åŒ– Prompt è§£å†³ï¼**

---

### 4. ä¿æŒæ›´æ–°

**AI é¢†åŸŸå‘å±•å¾ˆå¿«**

- å…³æ³¨ LangChain æ›´æ–°
- å…³æ³¨æ–°æ¨¡å‹å‘å¸ƒ
- å…³æ³¨æœ€ä½³å®è·µ
- å‚ä¸ç¤¾åŒºè®¨è®º

---

### 5. å®æˆ˜ä¸ºç‹

**æœ€å¥½çš„å­¦ä¹ æ–¹å¼æ˜¯åšé¡¹ç›®**

- ä»å°é¡¹ç›®å¼€å§‹
- é€æ­¥å¢åŠ å¤æ‚åº¦
- è§£å†³å®é™…é—®é¢˜
- ç§¯ç´¯ç»éªŒ

---

## æ€»ç»“

### æ ¸å¿ƒè·¯å¾„

```
LLM API â†’ LangChain â†’ Prompt â†’ RAG â†’ å¾®è°ƒ â†’ éƒ¨ç½²
```

### æœ€å°å­¦ä¹ é›†

**2-3 ä¸ªæœˆå³å¯ä¸Šæ‰‹**

- LLM API è°ƒç”¨
- LangChain åŸºç¡€
- Prompt Engineering
- RAG åŸºç¡€

### å…³é”®æŠ€èƒ½

- **LangChain**ï¼ˆå¿…é¡»ç²¾é€šï¼‰
- **Prompt Engineering**ï¼ˆå¿…é¡»ç²¾é€šï¼‰
- **RAG**ï¼ˆæ¨èæŒæ¡ï¼‰
- **å¾®è°ƒ**ï¼ˆæŒ‰éœ€å­¦ä¹ ï¼‰

### å­¦ä¹ å¿ƒæ€

- **å¿«é€Ÿä¸Šæ‰‹**ï¼ˆä¸è¦è¿½æ±‚å®Œç¾ï¼‰
- **è¾¹åšè¾¹å­¦**ï¼ˆå®è·µæœ€é‡è¦ï¼‰
- **æŒç»­è¿­ä»£**ï¼ˆä¸æ–­ä¼˜åŒ–ï¼‰
- **ä¿æŒå¥½å¥‡**ï¼ˆæ¢ç´¢æ–°æŠ€æœ¯ï¼‰

---

**ç¥ä½ å­¦ä¹ é¡ºåˆ©ï¼å¼€å§‹ä½ çš„ AI å¼€å‘ä¹‹æ—…å§ï¼ğŸš€**

*æœ€åæ›´æ–°ï¼š2026-01-27*
